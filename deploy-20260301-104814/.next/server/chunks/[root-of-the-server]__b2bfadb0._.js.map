{
  "version": 3,
  "sources": [],
  "debugId": "1414a243-48d4-a8b3-f16d-ebcb728203d8",
  "sections": [
    {"offset": {"line": 1, "column": 0}, "map": {"version":3,"sources":["../../../../../../ADK_WORKSPACE/TutorMekimi/tutorme-app/src/lib/db/index.ts"],"sourcesContent":["/* eslint-disable @typescript-eslint/no-explicit-any */\n/* eslint-disable @typescript-eslint/no-require-imports */\n\n/**\n * Database Client with Connection Pooling\n * \n * Features:\n * - Connection pooling for high concurrency (100+ users)\n * - Query caching with Redis\n * - Read replica support for scaling\n * - N+1 query prevention with dataloaders\n * \n * Note: Redis is lazily initialized to avoid bundling issues\n */\n\n// Connection pool configuration\nconst POOL_CONFIG = {\n  // Connection pool settings for 100+ concurrent users\n  min: 5,                    // Minimum connections\n  max: 50,                   // Maximum connections (supports 100+ concurrent users)\n  idleTimeoutMillis: 30000,  // Close idle connections after 30s\n  connectionTimeoutMillis: 5000, // Connection timeout\n  allowExitOnIdle: false,    // Keep pool alive\n}\n\n// Query cache configuration\nconst CACHE_CONFIG = {\n  ttl: 60,                   // Default cache TTL in seconds\n  staleWhileRevalidate: 30,  // Serve stale data while refreshing\n  prefix: 'tutorme:query:',  // Cache key prefix\n}\n\nlet db: any\nlet redis: any | null = null\nlet queryCache: Map<string, { data: any; expires: number }> | null = null\nlet redisInitialized = false\n\n// Safe check for server-side environment (not Edge Runtime)\n// Edge Runtime (used by Next.js middleware) doesn't support Prisma Client\nconst isEdgeRuntime = typeof (globalThis as any).EdgeRuntime !== 'undefined' || \n  (typeof process !== 'undefined' && process.env.NEXT_RUNTIME === 'edge')\nconst isServer = typeof window === 'undefined' && !isEdgeRuntime\n\n// Initialize in-memory cache only on server\nfunction getQueryCache() {\n  if (!isServer) return null\n  if (!queryCache) {\n    queryCache = new Map()\n  }\n  return queryCache\n}\n\n// Initialize Redis client if available (server-side only)\nasync function initRedis() {\n  if (!isServer) return null\n  if (redisInitialized) return redis\n  \n  try {\n    const redisUrl = process.env.REDIS_URL\n    if (!redisUrl) {\n      console.log('[DB] Redis URL not configured, using in-memory cache')\n      redisInitialized = true\n      return null\n    }\n    \n    // Dynamic import to avoid bundling issues\n    const { Redis } = await import('ioredis')\n    redis = new Redis(redisUrl, {\n      retryStrategy: (times) => Math.min(times * 50, 2000),\n      maxRetriesPerRequest: 3,\n    })\n    \n    redis.on('error', (err: any) => {\n      console.error('[Redis] Connection error:', err)\n      redis = null\n    })\n    \n    console.log('[DB] Redis cache initialized')\n    redisInitialized = true\n    return redis\n  } catch (e) {\n    console.warn('[DB] Failed to initialize Redis, using in-memory cache')\n    redisInitialized = true\n    return null\n  }\n}\n\n// Use Drizzle as the default database (server-side only)\nif (isServer) {\n  try {\n    const { drizzleDb } = require('./drizzle')\n    db = drizzleDb\n    console.log('[DB] Drizzle client (default db) initialized')\n  } catch (e) {\n    console.error('[DB] Failed to initialize Drizzle:', e)\n    db = {\n      $connect: async () => {},\n      $disconnect: async () => {},\n    } as any\n  }\n} else {\n  db = {\n    $connect: async () => {},\n    $disconnect: async () => {},\n  } as any\n}\n\n/**\n * Cache utilities\n */\nexport const cache = {\n  /**\n   * Ensure Redis is initialized\n   */\n  async ensureRedis() {\n    if (!isServer) return null\n    if (!redisInitialized) {\n      await initRedis()\n    }\n    return redis\n  },\n\n  /**\n   * Get cached value\n   */\n  async get<T>(key: string): Promise<T | null> {\n    if (!isServer) return null\n    \n    const fullKey = CACHE_CONFIG.prefix + key\n    \n    // Try Redis first\n    const client = await this.ensureRedis()\n    if (client) {\n      try {\n        const value = await client.get(fullKey)\n        if (value) return JSON.parse(value)\n      } catch (e) {\n        console.error('[Cache] Redis get error:', e)\n      }\n    }\n    \n    // Fallback to in-memory cache\n    const cache = getQueryCache()\n    if (!cache) return null\n    \n    const cached = cache.get(fullKey)\n    if (cached && cached.expires > Date.now()) {\n      return cached.data\n    }\n    \n    cache.delete(fullKey)\n    return null\n  },\n  \n  /**\n   * Set cached value\n   */\n  async set<T>(key: string, value: T, ttlSeconds = CACHE_CONFIG.ttl): Promise<void> {\n    if (!isServer) return\n    \n    const fullKey = CACHE_CONFIG.prefix + key\n    \n    // Try Redis first\n    const client = await this.ensureRedis()\n    if (client) {\n      try {\n        await client.setex(fullKey, ttlSeconds, JSON.stringify(value))\n        return\n      } catch (e) {\n        console.error('[Cache] Redis set error:', e)\n      }\n    }\n    \n    // Fallback to in-memory cache\n    const cache = getQueryCache()\n    if (cache) {\n      cache.set(fullKey, {\n        data: value,\n        expires: Date.now() + ttlSeconds * 1000\n      })\n    }\n  },\n  \n  /**\n   * Delete cached value\n   */\n  async delete(key: string): Promise<void> {\n    if (!isServer) return\n    \n    const fullKey = CACHE_CONFIG.prefix + key\n    \n    const client = await this.ensureRedis()\n    if (client) {\n      try {\n        await client.del(fullKey)\n      } catch (e) {\n        console.error('[Cache] Redis del error:', e)\n      }\n    }\n    \n    const cache = getQueryCache()\n    if (cache) cache.delete(fullKey)\n  },\n  \n  /**\n   * Clear all cached values\n   */\n  async clear(): Promise<void> {\n    if (!isServer) return\n    \n    const client = await this.ensureRedis()\n    if (client) {\n      try {\n        const keys = await client.keys(CACHE_CONFIG.prefix + '*')\n        if (keys.length > 0) {\n          await client.del(...keys)\n        }\n      } catch (e) {\n        console.error('[Cache] Redis clear error:', e)\n      }\n    }\n    \n    const cache = getQueryCache()\n    if (cache) cache.clear()\n  },\n  \n  /**\n   * Get or set cached value\n   */\n  async getOrSet<T>(\n    key: string,\n    factory: () => Promise<T>,\n    ttlSeconds = CACHE_CONFIG.ttl\n  ): Promise<T> {\n    const cached = await this.get<T>(key)\n    if (cached !== null) return cached\n    \n    const value = await factory()\n    await this.set(key, value, ttlSeconds)\n    return value\n  },\n\n  /**\n   * Invalidate cache for a pattern\n   */\n  async invalidatePattern(pattern: string): Promise<void> {\n    if (!isServer) return\n    \n    const client = await this.ensureRedis()\n    if (client) {\n      try {\n        const keys = await client.keys(CACHE_CONFIG.prefix + pattern)\n        if (keys.length > 0) {\n          await client.del(...keys)\n        }\n      } catch (e) {\n        console.error('[Cache] Pattern invalidation error:', e)\n      }\n    }\n    \n    // Clear in-memory cache matching pattern\n    const cache = getQueryCache()\n    if (cache) {\n      const regex = new RegExp(CACHE_CONFIG.prefix + pattern.replace('*', '.*'))\n      for (const key of cache.keys()) {\n        if (regex.test(key)) cache.delete(key)\n      }\n    }\n  }\n}\n\n/**\n * Query optimization utilities\n */\nexport const queryOptimizer = {\n  /**\n   * Batch load function for N+1 prevention\n   */\n  async batchLoad<T>(\n    ids: string[],\n    fetchFn: (ids: string[]) => Promise<T[]>,\n    getId: (item: T) => string\n  ): Promise<(T | null)[]> {\n    if (!isServer) return ids.map(() => null)\n    if (ids.length === 0) return []\n    \n    // Deduplicate IDs\n    const uniqueIds = [...new Set(ids)]\n    \n    // Fetch all items in one query\n    const items = await fetchFn(uniqueIds)\n    \n    // Create lookup map\n    const itemMap = new Map(items.map(item => [getId(item), item]))\n    \n    // Return items in original order\n    return ids.map(id => itemMap.get(id) || null)\n  },\n  \n  /**\n   * Wrap a query with caching\n   */\n  async cachedQuery<T>(\n    cacheKey: string,\n    queryFn: () => Promise<T>,\n    ttlSeconds = CACHE_CONFIG.ttl\n  ): Promise<T> {\n    return cache.getOrSet(cacheKey, queryFn, ttlSeconds)\n  }\n}\n\n/**\n * Read replica support (for future scaling)\n */\nexport const readReplica = {\n  /**\n   * Check if read replicas are configured\n   */\n  isConfigured(): boolean {\n    return isServer && !!process.env.DATABASE_READ_REPLICA_URL\n  },\n  \n  /**\n   * Get read-only database client\n   * Falls back to primary if replicas not configured\n   */\n  getClient() {\n    // For now, return the same client\n    // In production, this would return a connection to the read replica\n    return db\n  }\n}\n\nexport { db }\n/** Alias for code that imports prisma from @/lib/db â€” now points to Drizzle */\nexport const prisma = db\n\n// Server-only code that needs Drizzle: import { drizzleDb } from '@/lib/db/drizzle'\n// Legacy Prisma (scripts, pipl-compliance): import { prismaLegacyClient } from '@/lib/db/prisma-legacy'\n"],"names":[],"mappings":"sLA6BU,iBAIN,EAAoB,KACpB,EAAiE,KACjE,GAAmB,EAMjB,EAA4C,CAAC,CAF7B,KAA2C,EAEhD,EAFa,WAAmB,WAAW,EACtC,IAAnB,OAAO,SAA2B,CAA6B,EAIlE,CAHmC,QAG1B,WACP,AAAK,GACD,AAAC,CADD,EAEF,GAAa,CAFA,GAEI,EADF,CACE,EAEZ,GAJe,GAL0C,CAUlE,CAGA,eAAe,IACb,GAAI,CAAC,EAAU,OAAO,KACtB,GAAI,EAAkB,OAAO,EAE7B,GAAI,CACF,IAAM,EAAW,QAAQ,GAAG,CAAC,SAAS,CACtC,GAAI,CAAC,EAGH,OAFA,CADa,OACL,GAAG,CAAC,wDACZ,GAAmB,EACZ,KAIT,GAAM,OAAE,CAAK,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAalB,MAPA,CALA,EAAQ,IAAI,EAAM,EAAU,CAC1B,cAAe,AAAC,GAAU,KAAK,GAAG,CAAS,GAAR,EAAY,KAC/C,qBAAsB,CACxB,EAAA,EAEM,EAAE,CAAC,QAAS,AAAC,IACjB,QAAQ,KAAK,CAAC,4BAA6B,GAC3C,EAAQ,IACV,GAEA,QAAQ,GAAG,CAAC,gCACZ,GAAmB,EACZ,CACT,CAAE,MAAO,EAAG,CAGV,OAFA,QAAQ,IAAI,CAAC,0DACb,EAAmB,GACZ,IACT,CACF,CAGA,GAAI,EACF,GAAI,CACF,GAAM,CAFI,UAEF,CAAS,CAAE,CAAA,EAAA,CAAA,CAAA,QAEnB,QAAQ,GAAG,CAAC,+CACd,CAAE,MAAO,EAAG,CACV,QAAQ,KAAK,CAAC,qCAAsC,EAKtD,gBAWmB,CAIb,YAAN,SACE,AAAK,GACA,AAAD,CADA,EAEF,IAFa,EAEP,IAED,GAJe,EACC,GASzB,MAAM,IAAO,CAAW,EACtB,GAAI,CAAC,EAAU,OAAO,KAEtB,IAAM,EAAU,EAAsB,EAGhC,EAAS,MAAM,CAHQ,GAGJ,CAAC,EAHS,SAGE,GACrC,GAAI,EACF,GAAI,CACF,EAFQ,EAEF,EAAQ,MAAM,EAAO,GAAG,CAAC,GAC/B,GAAI,EAAO,OAAO,KAAK,KAAK,CAAC,EAC/B,CAAE,MAAO,EAAG,CACV,QAAQ,KAAK,CAAC,2BAA4B,EAC5C,CAIF,IAAM,EAAQ,IACd,GAAI,CAAC,EAAO,OAAO,KAEnB,IAAM,EAAS,EAAM,GAAG,CAAC,UACzB,AAAI,GAAU,EAAO,OAAO,CAAG,KAAK,GAAG,GAC9B,CADkC,CAC3B,IAAI,EAGpB,EAAM,MAAM,CAAC,GACN,KACT,EAKA,MAAM,IAAO,CAAW,CAAE,CAAQ,CAAE,IAA6B,EAC/D,GAAI,CAAC,EAAU,CADgC,MAG/C,IAAM,EAAU,CAH4C,CAGtB,EAGhC,EAAS,MAAM,CAHQ,GAGJ,CAAC,EAHS,SAGE,GACrC,GAAI,EACF,GAAI,CACF,EAFQ,IAEF,EAAO,KAAK,CAAC,EAAS,EAAY,KAAK,SAAS,CAAC,IACvD,MACF,CAAE,MAAO,EAAG,CACV,QAAQ,KAAK,CAAC,2BAA4B,EAC5C,CAIF,IAAM,EAAQ,IACV,GACF,EAAM,EADG,CACA,CAAC,EAAS,CACjB,KAAM,EACN,QAAS,KAAK,GAAG,GAAkB,IAAb,CACxB,EAEJ,EAKA,MAAM,OAAO,CAAW,EACtB,GAAI,CAAC,EAAU,OAEf,IAAM,EAAU,EAAsB,EAEhC,EAAS,MAAM,CAFQ,GAEJ,CAAC,EAFS,SAEE,GACrC,GAAI,EACF,GAAI,CACF,EAFQ,IAEF,EAAO,GAAG,CAAC,EACnB,CAAE,MAAO,EAAG,CACV,QAAQ,KAAK,CAAC,2BAA4B,EAC5C,CAGF,IAAM,EAAQ,IACV,GAAO,EAAM,MAAM,CAAC,EAC1B,EAKA,MAAM,QACJ,GAAI,CAAC,EAAU,OAEf,IAAM,EAAS,MAAM,IAAI,CAAC,WAAW,GACrC,GAAI,EACF,GAAI,CACF,EAFQ,EAEF,EAAO,MAAM,EAAO,IAAI,CAAC,EAAsB,KACjD,EAAK,IADmC,EAC7B,CAAG,GADgC,AAC7B,AACnB,MAAM,EAAO,GAAG,IAAI,EAExB,CAAE,MAAO,EAAG,CACV,QAAQ,KAAK,CAAC,6BAA8B,EAC9C,CAGF,IAAM,EAAQ,GACV,IAAO,EAAM,KAAK,EACxB,EAKA,MAAM,SACJ,CAAW,CACX,CAAyB,CACzB,EA7MG,EA6M0B,EAE7B,IAAM,EAAS,CAFF,KAEQ,IAAI,CAAC,GAAG,AAFH,CAEO,GACjC,GAAe,OAAX,EAAiB,OAAO,EAE5B,IAAM,EAAQ,MAAM,IAEpB,OADA,MAAM,IAAI,CAAC,GAAG,CAAC,EAAK,EAAO,GACpB,CACT,EAKA,MAAM,kBAAkB,CAAe,EACrC,GAAI,CAAC,EAAU,OAEf,IAAM,EAAS,MAAM,IAAI,CAAC,WAAW,GACrC,GAAI,EACF,GAAI,CACF,EAFQ,EAEF,EAAO,MAAM,EAAO,IAAI,CAAC,EAAsB,GACjD,EAAK,MADmC,AAC7B,CAAG,GAAG,AACnB,EAFgD,IAE1C,EAAO,GAAG,IAAI,EAExB,CAAE,MAAO,EAAG,CACV,QAAQ,KAAK,CAAC,sCAAuC,EACvD,CAIF,IAAM,EAAQ,IACd,GAAI,EAAO,CACT,IAAM,EAAQ,IAAI,OAAO,EAAsB,EAAQ,OAAO,CAAC,CAAzB,GAA8B,GAAxB,IAC5C,IAAK,IAAM,KAAO,EAAM,IAAI,GAAI,AAC1B,EAAM,IAAI,CAAC,IAAM,EAAM,MAAM,CAAC,EAEtC,CACF,CACF"}}]
}